\section{Related work}

An alternative to directed graphical models with latent variables are undirected graphical models with latent variables, such as restricted Boltzmann machines (RBMs) \cite{27_10.7551/mitpress/5236.003.0009,16_10.1162/neco.2006.18.7.1527}, deep Boltzmann machines (DBMs) \cite{26_salakhutdinov2009deep} and their numerous variants. The interactions within such models are represented as the product of unnormalized potential functions, normalized by a global summation/integration over all states of the random variables. This quantity (the \emph{partition function}) and its gradient are intractable for all but the most trivial instances, although they can be estimated by Markov chain Monte Carlo (MCMC) methods. Mixing poses a significant problem for learning algorithms that rely on MCMC \cite{3_pmlr-v28-bengio13,5_bengio2014deepgenerativestochasticnetworks}.

\noindent Deep belief networks (DBNs)\index{generative models} \cite{16_10.1162/neco.2006.18.7.1527} are hybrid models containing a single undirected layer and several directed layers. While a fast approximate layer-wise training criterion exists, DBNs incur the computational difficulties associated with both undirected and directed models.

\noindent Alternative criteria that do not approximate or bound the log-likelihood have also been proposed, such as score matching \cite{18_JMLR:v6:hyvarinen05a}\index{generative models} and noise-contrastive estimation (NCE) \cite{13_pmlr-v9-gutmann10a}. Both of these require the learned probability density to be analytically specified up to a normalization constant. Note that in many interesting generative models with several layers of latent variables (such as DBNs and DBMs), it is not even possible to derive a tractable unnormalized probability density. Some models such as denoising auto-encoders \cite{30_vincent2008extracting} and contractive autoencoders have learning rules very similar to score matching applied to RBMs. In NCE, as in this work, a discriminative training criterion is employed to Ô¨Åt a generative model. However, rather than fitting a separate discriminative model, the generative model itself is used to discriminate generated data from samples a fixed noise distribution. Because NCE uses a fixed noise distribution, learning slows dramatically after the model has learned even an approximately correct distribution over a small subset of the observed variables.

\noindent Finally, some techniques do not involve defining a probability distribution explicitly, but rather train a generative machine to draw samples from the desired distribution. This approach has the advantage that such machines can be designed to be trained by back-propagation. Prominent recent work in this area includes the generative stochastic network (GSN) framework \cite{5_bengio2014deepgenerativestochasticnetworks}, which extends generalized denoising auto-encoders \cite{4_NIPS2013_559cb990}: oth can be seen as defining a parameterized Markov chain, i.e., one learns the parameters of a machine that performs one step of a generative Markov chain. Compared to GSNs, the adversarial nets framework does not require a Markov chain\index{markov chain} for sampling. Because adversarial nets\index{adversarial nets} do not require feedback loops during generation, they are better able to leverage piecewise linear units \cite{19_5459469,9_pmlr-v15-glorot11a,10_goodfellow2013maxoutnetworks}, which improve the performance of backpropagation but have problems with unbounded activation when used ina feedback loop. More recent examples of training a generative machine by back-propagating into it include recent work on auto-encoding variational Bayes \cite{20_kingma2022autoencodingvariationalbayes} and stochastic backpropagation \cite{24_rezende2014stochasticbackpropagationapproximateinference}.
